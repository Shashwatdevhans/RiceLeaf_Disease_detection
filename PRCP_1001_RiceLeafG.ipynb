{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "TeamId: PTID-CDS-NOV-24-2192<br>\n",
    "ProjectID: PRCP- 1001- RiceLeaf disease detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cultivation and harvesting of rice involves several processes, similar to those of other crops. However, rice crops are susceptible to diseases, which can be identified through their leaves. This notebook demonstrates how Convolutional Neural Networks (CNNs) can be utilized to detect diseases by training on pre-captured images of rice leaves, with a primary focus on bacterial damage, brown spot, and leaf smut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MamE6OEtKbV_",
    "outputId": "39df8172-9576-4f30-c912-50ccce22a8a3"
   },
   "outputs": [],
   "source": [
    "filepath=\"/Data.zip\"\n",
    "# filepath=\"zip only\"\n",
    "from zipfile import ZipFile\n",
    "try:\n",
    "  with ZipFile(filepath,'r') as zip:\n",
    "    zip.extractall()\n",
    "    print('Done')\n",
    "except FileNotFoundError:\n",
    "  print('File Not Found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6l9ps2eOG9j_"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator as dg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EvRHBUROKG0B",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Structured data **preparation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oy-yF2MCSh6N"
   },
   "source": [
    "## Preparation for Traing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qDLlYOPb4dHY"
   },
   "outputs": [],
   "source": [
    "path_for_training_data = \"/content/Data/tRaning_Data\"\n",
    "path_for_validation_data=\"/content/Data/vAlidation_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2-ahPr3MJ2YT",
    "outputId": "d65eaf69-9280-4ea7-fbfd-c7a3fa73783d"
   },
   "outputs": [],
   "source": [
    "train_Datagen=dg(rescale=1./255, #To scale from pixal 0 to 1\n",
    "                shear_range=0.2,\n",
    "                zoom_range=0.2,\n",
    "                horizontal_flip=True,\n",
    "                preprocessing_function= lambda img : 255 - img ) #negative Image For Negative Gradiant\n",
    "\n",
    "\n",
    "training_set = train_Datagen.flow_from_directory(path_for_training_data,\n",
    "                                                 target_size=(64,64),\n",
    "                                                 batch_size=32,\n",
    "                                                 class_mode='categorical')\n",
    "\n",
    "class_labels = list(training_set.class_indices.keys()) # get class labels from training_set\n",
    "print(class_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YOcrW-E5SPm3"
   },
   "source": [
    "## **Preparation for validation dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qY6tcySPSW4I",
    "outputId": "568ac9eb-6363-4496-c4ed-0d9fd8333a1b"
   },
   "outputs": [],
   "source": [
    "test_datagen = dg(rescale = 1./255)\n",
    "\n",
    "\n",
    "\n",
    "validation_dataset = test_datagen.flow_from_directory(path_for_validation_data,\n",
    "                                                 target_size=(64,64),\n",
    "                                                 batch_size=32,\n",
    "                                                 class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ATstHNsUWbi",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# **Building A CNN network with very Basic construction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ycaUnVKoWl8c"
   },
   "outputs": [],
   "source": [
    "seq = Sequential()\n",
    "#input Layer or First Layer in CNN\n",
    "seq.add(Conv2D(filters=32,kernel_size=(3,3),activation='relu',input_shape=[64,64,3]))\n",
    "seq.add(MaxPool2D(pool_size=(2,2),strides=1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ATPV27KrZg6t"
   },
   "source": [
    "## **Flattening**\n",
    "### Above this block ***CNN*** and Below this block ***ANN*** part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gn0Ccm3kZgUj"
   },
   "outputs": [],
   "source": [
    "seq.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2p21p-tSZziA"
   },
   "source": [
    "## **ANN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CP4X8_b19R4q"
   },
   "outputs": [],
   "source": [
    "# First layer on ANN\n",
    "seq.add(Dense(units=128,activation='relu'))\n",
    "\n",
    "# output Layer\n",
    "seq.add(Dense(units=3,activation='softmax'))\n",
    "\n",
    "# set Compiler\n",
    "seq.compile(optimizer='adam' , loss='categorical_crossentropy' , metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4OQ9Llwk5Lyu",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Simple **CNN** Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "vbvPA3VijKQk",
    "outputId": "defe0471-8b91-4ef6-9025-076dfb21b97f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def simple_Cnn():\n",
    "  seq = tf.keras.models.Sequential()\n",
    "  seq.add(Conv2D(filters=32,kernel_size=(3,3),activation='relu',input_shape=[64,64,3]))\n",
    "  seq.add(MaxPooling2D(pool_size=(2,2),strides=1))\n",
    "  seq.add(Flatten())\n",
    "  seq.add(tf.keras.layers.Dense(units=128,activation='relu'))\n",
    "  seq.add(tf.keras.layers.Dense(units=3,activation='softmax'))\n",
    "  seq.compile(optimizer='adam' , loss='categorical_crossentropy' , metrics=['accuracy'])\n",
    "  return seq\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vMC7yMaHdeRC"
   },
   "outputs": [],
   "source": [
    "modelCnn = seq.fit(x=training_set,validation_data=validation_dataset,epochs=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BHu7keuCkeIU"
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "def iterate_and_predict(data_dir, datagen, model):\n",
    "  for root, dirs, files in os.walk(data_dir):\n",
    "    for file in files:\n",
    "      if file.lower().endswith(('.png', '.jpg', '.jpeg')):  # Check for image files\n",
    "\n",
    "        image_path = os.path.join(root, file)\n",
    "        # Load and preprocess the image\n",
    "        img = tf.keras.preprocessing.image.load_img(image_path, target_size=(64, 64))\n",
    "        img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "        img_array = img_array / 255.0\n",
    "        img_array = tf.expand_dims(img_array, 0)\n",
    "\n",
    "        # Make prediction\n",
    "        predictions = model.predict(img_array)\n",
    "        # Process the prediction\n",
    "        predicted_class = tf.argmax(predictions, axis=1)  # Get class index with highest probability\n",
    "        class_labels = list(training_set.class_indices.keys()) # get class labels from training_set\n",
    "        predicted_label = class_labels[predicted_class[0]]\n",
    "\n",
    "\n",
    "        print(f\"File: {file} || Predicted Class: || {predicted_label} || Predictions: {predictions}\")\n",
    "\n",
    "\n",
    "AlienDatapath= \"/content/Data/Alien_data\"\n",
    "iterate_and_predict(AlienDatapath, test_datagen,modelCnn.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AdEMaOConCi8"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NyifdE_HkxHG",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Modefied VGG-16 Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NyifdE_HkxHG",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Key Characteristics:\n",
    "\n",
    "Depth: VGG-16 is characterized by its depth, consisting of 16 layers, including 13 convolutional layers and 3 fully connected layers.\n",
    "Uniformity: The architecture features a stack of convolutional layers followed by max-pooling layers, with progressively increasing depth. This uniform design makes it relatively simple to understand and implement. Â  \n",
    "Small Filter Sizes: VGG-16 uses small 3x3 convolutional filters throughout the network, which has been shown to be more effective than larger filters.\n",
    "Advantages:\n",
    "\n",
    "Strong Performance: VGG-16 has demonstrated strong performance on various computer vision tasks, including image classification and object recognition.\n",
    "Simplicity: The uniform architecture and small filter sizes make VGG-16 relatively easy to understand and implement.\n",
    "Transfer Learning: Pre-trained VGG-16 models can be used as a starting point for transfer learning, which can significantly improve the performance of models on new tasks with limited data.\n",
    "Disadvantages:\n",
    "\n",
    "Computational Cost: The depth of VGG-16 and the large number of parameters can make it computationally expensive to train and use.\n",
    "Memory Requirements: The large number of parameters also requires significant memory resources.\n",
    "Vanishing Gradients: The deep architecture can be prone to vanishing gradients during training, which can slow down the learning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 870
    },
    "id": "J0Ot1meSk2UU",
    "outputId": "678debde-2b67-4d78-c10c-be3f4dd1c3cc"
   },
   "outputs": [],
   "source": [
    "def create_vgg16():\n",
    "    model = Sequential()\n",
    "    # just try with image 128 and w'll see the gradient vanishing on marked point\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu')) # vanishing point\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(2048, activation='relu'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    model.compile(optimizer='adam' , loss='categorical_crossentropy' , metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dj9UtobxqFb8",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Modefied AlexNet Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dj9UtobxqFb8",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Key Characteristics:\n",
    "\n",
    "Depth: AlexNet consists of eight layers, including five convolutional layers and three fully connected layers.\n",
    "ReLU Activation: AlexNet employed the ReLU (Rectified Linear Unit) activation function, which addressed the vanishing gradient problem and improved training efficiency.\n",
    "GPU Acceleration: AlexNet was one of the first deep learning models to leverage the power of GPUs for training, significantly accelerating the training process.\n",
    "Advantages:\n",
    "\n",
    "State-of-the-Art Performance: AlexNet achieved groundbreaking performance on the ImageNet dataset, significantly surpassing previous methods.\n",
    "ReLU Activation: The use of ReLU activation function improved training speed and accuracy compared to traditional activation functions like sigmoid and tanh.\n",
    "GPU Acceleration: The utilization of GPUs for training enabled faster and more efficient training of deep neural networks.\n",
    "Disadvantages:\n",
    "\n",
    "Large Model Size: AlexNet is a relatively large model with a significant number of parameters, which can make it computationally expensive to train and deploy.\n",
    "Overfitting: AlexNet can be prone to overfitting, especially when trained on smaller datasets. Techniques like data augmentation and dropout were used to mitigate this issue.\n",
    "Limited Applicability to Small Datasets: Due to its large size and complexity, AlexNet may not be suitable for training on smaller datasets, as it may require a large amount of data to avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 602
    },
    "id": "Gh6_4xMDlnxO",
    "outputId": "9131a2a2-d86e-4cc9-993d-c3d0d88af317"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "def create_alexnet():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(128, (11, 11), activation='relu', input_shape=(128, 128, 3)))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=2))\n",
    "    model.add(Conv2D(16, (5, 5), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=2))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    model.compile(optimizer='adam' , loss='categorical_crossentropy' , metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KzFv5rM0dDbX"
   },
   "source": [
    "# Model Creation and summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dZDODMrXa0IY"
   },
   "outputs": [],
   "source": [
    "# Modefied VGG-16 Architecture\n",
    "model_Alex = create_alexnet()\n",
    "model_Alex.summary()\n",
    "\n",
    "# Modefied VGG-16 Architecture\n",
    "model_vgg16 = create_vgg16()\n",
    "model_vgg16.summary()\n",
    "\n",
    "# Simple **CNN** Architecture\n",
    "model_simple_CNN = simple_Cnn()\n",
    "model_simple_CNN.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U-TW_wxeBZn_"
   },
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v5v_KRGHbAP_",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Pre_Training_Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WxjkpIzDVSRn"
   },
   "outputs": [],
   "source": [
    "def pre_trainingCheckpoints(T_set,V_set,model,C_P='pre_model'):\n",
    "\n",
    "  from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "  C_P = C_P + '.keras'\n",
    "\n",
    "  # created a checkpoint and save the best training output\n",
    "  model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath = C_P,\n",
    "    save_weights_only = False,\n",
    "    monitor = 'val_accuracy',\n",
    "    mode = 'max',\n",
    "    save_best_only = True)\n",
    "\n",
    "  # pre_training\n",
    "  preModel = model.fit(\n",
    "    x=T_set,\n",
    "    validation_data=V_set,\n",
    "    epochs=5,\n",
    "    batch_size=1,\n",
    "    callbacks=[model_checkpoint_callback])\n",
    "\n",
    "  return preModel , C_P\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6vcir_02bSkc"
   },
   "outputs": [],
   "source": [
    "\n",
    "model_simple_CNN,filepathS = pre_trainingCheckpoints(training_set,validation_dataset,model_simple_CNN,'SimpleCnn_pre_model')\n",
    "\n",
    "model_Alex,filepathA = pre_trainingCheckpoints(training_set,validation_dataset,model_Alex,'SimpleCnn_pre_model')\n",
    "\n",
    "model_vgg16,filepathV = pre_trainingCheckpoints(training_set,validation_dataset,model_vgg16,'SimpleCnn_pre_model')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s731Cj-9dsgV"
   },
   "source": [
    "# Fitting the model and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6NyYW_bxO0mS",
    "outputId": "3276b918-6a27-4507-9eb2-9dbb56516566"
   },
   "outputs": [],
   "source": [
    "# From pretrained File\n",
    "\n",
    "saved_model = tf.keras.models.load_model(filepathS) \n",
    "\n",
    "EvCNN = saved_model.fit(\n",
    "                          x=training_set,\n",
    "                          validation_data=validation_dataset,\n",
    "                          epochs=5,\n",
    "                          batch_size=3,\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCnn = model_simple_CNN.fit(\n",
    "                          x=training_set,\n",
    "                          validation_data=validation_dataset,\n",
    "                          epochs=35,\n",
    "                          batch_size=11,\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACnn = model_Alex.fit(\n",
    "                          x=training_set,\n",
    "                          validation_data=validation_dataset,\n",
    "                          epochs=21,\n",
    "                          batch_size=11,\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VCnn = model_vgg16.fit(\n",
    "                          x=training_set,\n",
    "                          validation_data=validation_dataset,\n",
    "                          epochs=19,\n",
    "                          batch_size=11,\n",
    "                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Model Graph Representation with Accuracy and Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6NyYW_bxO0mS",
    "outputId": "3276b918-6a27-4507-9eb2-9dbb56516566"
   },
   "outputs": [],
   "source": [
    "def model_evaluation(modelCnn):\n",
    "  test_loss, test_acc = modelCnn.model.evaluate(validation_dataset)\n",
    "  print(f\"Validation Accuracy: {test_acc * 100:.2f}%\")\n",
    "\n",
    "  plt.plot(modelCnn.history['accuracy'], label='Training Accuracy')\n",
    "  plt.plot(modelCnn.history['val_accuracy'], label='Validation Accuracy')\n",
    "  plt.xlabel('Epochs')\n",
    "  plt.ylabel('Accuracy')\n",
    "  plt.legend()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H4LHjXekrUI8"
   },
   "outputs": [],
   "source": [
    "# Simple Model\n",
    "model_evaluation(SCnn)\n",
    "# AlexNet\n",
    "model_evaluation(ACnn)\n",
    "# VGG-16\n",
    "model_evaluation(VCnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LqzJVgQoUm_F",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Custome File Prediction\n",
    "> Pest your image file on Alien_Data Folder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a7l05y7s6uu-",
    "outputId": "c0a97fa6-2909-4fb8-fafe-181335f8e7c9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "path= \"Data/Alien_Data/\"\n",
    "\n",
    "# saved_model = tf.keras.models.load_model('best_model.keras')\n",
    "\n",
    "def dir_images(path,model):\n",
    "    for fileName in os.listdir(path):\n",
    "        if fileName.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            # Image importation form Dir\n",
    "            img = tf.keras.preprocessing.image.load_img(path+fileName, target_size=(64, 64))\n",
    "            img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "            img_array = img_array / 255.0\n",
    "            img_array = tf.expand_dims(img_array, 0)\n",
    "\n",
    "            # Process the prediction\n",
    "            predictions = model.predict(img_array)\n",
    "            predicted_class = tf.argmax(predictions, axis=1)\n",
    "            class_labels = list(training_set.class_indices.keys())\n",
    "            predicted_label = class_labels[predicted_class[0]]\n",
    "            print(f\"Prediction for {fileName}: ----> {predicted_label}\")\n",
    "\n",
    "dir_images(path,saved_model) # pass direct model or select from the file if .keras file Exist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c_caboebeJBE"
   },
   "source": [
    "# Project Summary\n",
    ">> A Neural network is a complex and powerful method and, on the otherhand very sensitive with parameter change.<br>\n",
    ">> Image quality is crucial, image must be ensuring proper object clarity.<br>\n",
    ">> For high-performance processing, one can save the learning progress to a file and subsequently proceed through each epoch, monitoring the accuracy.<br>\n",
    ">> The graph illustrates the validation and training performance throughout each epoch.<br>\n",
    "\n",
    "\n",
    ">> Modified version of different architecture are used here<br>\n",
    ">> Custom prediction methods allows you to product with your images<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challages\n",
    ">>**Data Requirements**: CNNs typically require large amounts of labeled data for effective training. Acquiring and labeling such datasets can be time-consuming and expensive.<br>\n",
    "\n",
    ">>**Computational Costs**: Training CNNs can be computationally expensive, especially for deep architectures. This necessitates powerful hardware resources and can make training time extensive.<br>\n",
    "Â  \n",
    ">>**Overfitting**: CNNs can be prone to overfitting, where the model performs well on the training data but poorly on unseen data. Techniques like regularization and data augmentation are used to mitigate this.<br>\n",
    " \n",
    ">>**Interpretability**: CNNs are often considered \"black box\" models, making it difficult to understand why they make certain predictions. This lack of transparency can be a concern in critical applications.<br>\n",
    " \n",
    ">>**Hardware Limitations**: Training and deploying large CNN models can be challenging due to memory and processing power limitations of available hardware.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Vanishing\n",
    "\n",
    "In essence: Gradient vanishing is a phenomenon that occurs during the training of deep neural networks, particularly those with many layers. It refers to the situation where the gradients of the loss function with respect to the earlier layers in the network become extremely small. Â  \n",
    "\n",
    "Impact:\n",
    "\n",
    "Slow Training: As gradients approach zero, the weight updates during backpropagation become very small. This significantly slows down the training process, making it difficult for the network to learn effectively. Â  \n",
    "Difficulty in Learning Deeper Representations: Smaller gradients hinder the flow of information from later layers to earlier layers. This prevents the network from learning meaningful representations in the initial layers, which are crucial for capturing essential features. Â  \n",
    "Why it happens:\n",
    "\n",
    "Chain Rule: Backpropagation relies on the chain rule to compute gradients for each layer. In deep networks, the repeated multiplication of small gradients across many layers leads to a product that quickly approaches zero. Â  \n",
    "Activation Functions: Some activation functions, like sigmoid and tanh, tend to saturate (produce outputs close to their limits) in certain regions. This can result in very small derivatives, contributing to the vanishing gradient problem. Â  \n",
    "Mitigation Strategies:\n",
    "\n",
    "ReLU (Rectified Linear Unit): ReLU is a popular activation function that helps alleviate vanishing gradients. It introduces non-linearity without saturating for positive inputs, leading to larger gradients. Â  \n",
    "Leaky ReLU, ELU, etc.: Variants of ReLU (like Leaky ReLU, ELU) address the \"dying ReLU\" problem (where ReLU units can become inactive) and further improve gradient flow. Â  \n",
    "Batch Normalization: This technique helps stabilize the training process by normalizing the activations of each layer, reducing internal covariate shift and improving gradient flow. Â  \n",
    "Residual Connections: Skip connections in residual networks allow gradients to flow more directly through the network, bypassing some layers and preventing them from vanishing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>The End</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "oy-yF2MCSh6N",
    "YOcrW-E5SPm3",
    "9ATstHNsUWbi",
    "2p21p-tSZziA",
    "4OQ9Llwk5Lyu",
    "NyifdE_HkxHG",
    "Dj9UtobxqFb8",
    "KzFv5rM0dDbX"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
